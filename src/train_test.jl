
"""
Given a â„Vector( Vector of Hermitian matrices), weights(optional), returns a vector containing
the mapping of these matrices in the tangent space of the data set mean. Vectorization is
done along with the mapping.
The relation employed for mapping is the following logarithmic relation:
        ``(GÂ½ * log(â„(Gâ»Â½ * ğ[i] * Gâ»Â½)) * GÂ½)``
where G is the data set mean and ğ[i] the set of points to be mapped.
For the better understanding of this mapping, one may refer to the [logMap function
in PostDefManifold](https://marco-congedo.github.io/PosDefManifold.jl/latest/riemannianGeometry/#PosDefManifold.logMap).

Arguments:

- `ğ::â„Vector`              :- Vector of Hermitian matrices or simply a HermitianVector.
                                     The vector of points in the *Symmetric Positive Definite*
                                     manifold to be transformed into the the tangent space.

*The following parameters are needed for mean computation only:*

- `w::Vector(optional)`:- Vector containing weights corresponding to every point
                                     in ğ.
- `âœ“w = true(optional)`     :- Boolean to determine whether to calculate weighted mean
                                     or just take w = []. It also checks if the weights
                                     sum up to 1. If not does normalization.
- `â© = false (optional)`    :- Boolean to allow threading or not.

Returns:

- `Vec :: Array{Float64, 2}` :-Vector of all the points in the training set.

"""
function logMap(ğ::â„Vector; metric :: Metric = Fisher, w::Vector=[], âœ“w=true, â©=false)
    G = mean(metric, ğ; w=w, âœ“w=âœ“w, â©=â©)
    len = dim(ğ,1)
    Vec = Array{Float64, 2}(undef, dim(ğ,1), Int(dim(ğ,2)*(dim(ğ,2)+1)/2) )
    GÂ½, Gâ»Â½ = pow(G, 0.5, -0.5)
    @threads for i = 1:len
        Vec[i,:] = vecP(â„( log(â„(Gâ»Â½ * ğ[i] * Gâ»Â½)) ))
        #Vec[i,:] = vecP(â„(GÂ½ * log(â„(Gâ»Â½ * ğ[i] * Gâ»Â½)) * GÂ½))
    end
    return Vec
end

"""
Given a model, â„Vector(training set), y(labels), weights(optional), checks
the type of model and then fits the model to the given training set.
This function is an overwriting of the default fit! function available in the
ScikitLearn.jl package. The function also prints the average
regular score for all models except mdm.

Arguments :

- `model::RiemannianML object`:- Classifier model instance eg. kneighbhorClf(),
                                   LogisticReg() or others. The model which is to
                                   be trained or to which the given data is to be fit.
                                   The instance should be created before calling fit! to
                                   train it.

- `ğ—::â„Vector`               :- Vector of Hermitian matrices or simply a HermitianVector.
                                  The vector of points in the training set consisting of
                                  *Symmetric Positive Definite* manifold matrices.
- `y :: Int[]`               :- Vector of intrger labels corresponding to each sample in the
                                  training set.
- `w::Vector(optional)` :- Vector containing weights corresponding to every point
                                  in ğ—. *Only for mdm models.*
- `âœ“w = true(optional)`      :- Boolean to determine whether to calculate weighted mean
                                  or just take w = [].It also checks if the weights
                                  sum up to 1. If not does normalization.

Returns:
(A value is returned only in case the model is an mdm object)

- `class_means`              :- List of means corresponding to all the classes for the
                                    given training set.


    ## Example
    model1 = kneighborClf(n_neighbors=3)
    model2 = LogisticReg()
    model3 = MDM(Fisher)
    ğ— = *load data...*
    y = *load labels...*
    fit!(model1, ğ—,y)
    fit!(model2, ğ—,y)
    fit!(model3, ğ—,y)

"""
function fit!(model, ğ— :: â„Vector, y; w::Vector=[], âœ“w = true)
    if isa(model, MDM)
        y1 = copy(y)
        classes = unique!(y1)
        ğ‹ = [â„[] for i = 1: length(classes)]
        W = [Float64[] for i = 1:length(classes)]
        for j = 1:dim(ğ—,1)
            push!(ğ‹[Int(y[j])],ğ—[j])
            if !(isempty(w))    push!(W[Int(y[j])], w[j])  end #---non efficient-----------------------
        end
        model.class_means = [mean_mdm(Fisher, ğ‹[Int(l)], w = W[Int(l)], â©=true ) for l= 1:length(classes)]
        return model.class_means
    else
        Z = logMap(ğ—)
        fit!(model.clf, Z, y)
        println(score(model.clf, Z,y))
    end
end

"""
Given a trained model and the sample set, gives the predicted class for
the data points in the sample set. This function is an overwriting of the default predict function available in
the ScikitLearn.jl package.

Arguments :

- `model::RiemannianML object`:- Classifier model instance eg. kneighbhorClf(),
                                       LogisticReg() or others. The model which is already
                                       been trained according to a training set can only be
                                       used as an argument here. The instance should be
                                       created and fit before calling predict on it.
- `samp::â„Vector`             :- The vector of Hermitian matrices or points in
                                       the positive definite manifold for which the
                                       prediction is to be made using the model(argument 1)
                                       already been trained specially for it.

Returns :

- `Predicted classes`        :- The List of the predicted classes for the given
                                    sample set.


    ## Example
    # following the above code for fit!
    predict(model1, ğ—)
    predict(model2, ğ—)
    predict(model3, ğ—)


"""
function predict(model,samp)
    if isa(model,MDM)
        predict_mdm(samp, model.class_means, model.metric)
    else
        return (model.clf.predict(logMap(samp)))
    end
end


"""
Given a model, â„Vector(training set), y(labels), cv(number of cross-validations) returns
the the list containing the score for each cross-validation iteration.
This function is an overwriting of the default cross_val_score function available in
the ScikitLearn.jl package.

Arguments :

- `model::RiemannianML object`:- Classifier model instance eg. kneighbhorClf(),
                                       LogisticReg() or others i,e. the model whose
                                       evaluation using cross-validation is to be done.
- `ğ—::â„Vector`                :- Vector of Hermitian matrices or simply a HermitianVector.
                                       The vector of points in the training set consisting of
                                       *Symmetric Positive Definite* manifold matrices. The
                                       training set on the basis of which the evaluation
                                       of the given model is to be done.
- `y :: Int[]`                :- Vector of intrger labels corresponding to each sample in the
                                       training set.
- `cv :: Int(optional)`       :- The number of cross-validation desired by the user.
                                       The default value is set to 5.

*These arguments are only applicable if the model is mdm type* :

- `scoring :: String`      :- If Balanced Accuracy is requied or the Regular Accuracy.
                                    The default is set to Balanced Accuracy.
- `cnfmat :: Bool`         :- Boolean to notify if the user wants the confusion matrix also.
                               Default is set to false.

Returns :

- `cross_val score`          :- The list containing the score for each cross_val
                                    iteration.


       ## Example
       model1 = kneighborClf(n_neighbors=3)
       model2 = LogisticReg()
       model3 = MDM(Fisher)
       ğ— = *load data...*
       y = *load labels...*
       println(cross_val_score(model1,ğ—,y))
       println(cross_val_score(model2,ğ—,y))
       cross_val_score(model5, ğ—,y)


"""
function cross_val_score(model, ğ—::â„Vector, y;cv = 5, scoring :: String = "bal", cnfmat :: Bool = false)
     if isa(model, MDM)
         cross_val_mdm(ğ—,y,cv)
     else
         return (cross_val_score(model.clf, logMap(ğ—), y,cv = cv))
     end
end
